{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe see also:\n",
    "    - https://devopscube.com/run-docker-in-docker/\n",
    "    - https://blog.skbali.com/2019/05/mongodb-replica-set-using-docker-compose/\n",
    "    - https://gist.github.com/psychemedia/67a1c27ae1b0f0cee7ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pymongo\n",
    "#%pip install --upgrade https://github.com/docker/docker-py/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "\n",
    "#Connect to docker\n",
    "client = docker.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some helper functions via https://github.com/docker/docker-py\n",
    "\n",
    "#Equivalent of docker ps\n",
    "def docker_ps(c):\n",
    "    return c.containers(quiet=False, all=False, trunc=True, latest=False, since=None, before=None, limit=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Container: 9d2d38fd4d>, <Container: bc2fc497a9>, <Container: c2e7b1092b>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.containers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9d2d38fd4d7816aa0806bd9453525db89992db4bb38c576c9972c0bdebb4be1b',\n",
       " 'bc2fc497a9f03af1296bb72f94e243fe816984098627e8679e5bbd24193bb3ed',\n",
       " 'c2e7b1092bbf4b096afb871eb081d8ffbc2fbe97734d59a3970dab3ab962820f']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container_ids = [c.id for c in client.containers.list()]\n",
    "container_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Id': '9d2d38fd4d7816aa0806bd9453525db89992db4bb38c576c9972c0bdebb4be1b',\n",
       " 'Created': '2020-11-04T16:08:16.1045496Z',\n",
       " 'Path': '/usr/bin/mongod',\n",
       " 'Args': ['--bind_ip_all', '--replSet', 'devrs'],\n",
       " 'State': {'Status': 'running',\n",
       "  'Running': True,\n",
       "  'Paused': False,\n",
       "  'Restarting': False,\n",
       "  'OOMKilled': False,\n",
       "  'Dead': False,\n",
       "  'Pid': 3966,\n",
       "  'ExitCode': 0,\n",
       "  'Error': '',\n",
       "  'StartedAt': '2020-11-04T16:08:16.962193Z',\n",
       "  'FinishedAt': '0001-01-01T00:00:00Z'},\n",
       " 'Image': 'sha256:525bd2016729a161cffa87b2ab606afabc5d95e744077259613d77b22533a3de',\n",
       " 'ResolvConfPath': '/var/lib/docker/containers/9d2d38fd4d7816aa0806bd9453525db89992db4bb38c576c9972c0bdebb4be1b/resolv.conf',\n",
       " 'HostnamePath': '/var/lib/docker/containers/9d2d38fd4d7816aa0806bd9453525db89992db4bb38c576c9972c0bdebb4be1b/hostname',\n",
       " 'HostsPath': '/var/lib/docker/containers/9d2d38fd4d7816aa0806bd9453525db89992db4bb38c576c9972c0bdebb4be1b/hosts',\n",
       " 'LogPath': '/var/lib/docker/containers/9d2d38fd4d7816aa0806bd9453525db89992db4bb38c576c9972c0bdebb4be1b/9d2d38fd4d7816aa0806bd9453525db89992db4bb38c576c9972c0bdebb4be1b-json.log',\n",
       " 'Name': '/mongo2',\n",
       " 'RestartCount': 0,\n",
       " 'Driver': 'overlay2',\n",
       " 'Platform': 'linux',\n",
       " 'MountLabel': '',\n",
       " 'ProcessLabel': '',\n",
       " 'AppArmorProfile': '',\n",
       " 'ExecIDs': None,\n",
       " 'HostConfig': {'Binds': ['/home/jovyan/data2/configdb:/data/configdb:rw',\n",
       "   '/home/jovyan/data2/db:/data/db:rw'],\n",
       "  'ContainerIDFile': '',\n",
       "  'LogConfig': {'Type': 'json-file', 'Config': {}},\n",
       "  'NetworkMode': 'jovyan_mongo-dev-net',\n",
       "  'PortBindings': {'27017/tcp': [{'HostIp': '', 'HostPort': '30002'}]},\n",
       "  'RestartPolicy': {'Name': 'always', 'MaximumRetryCount': 0},\n",
       "  'AutoRemove': False,\n",
       "  'VolumeDriver': '',\n",
       "  'VolumesFrom': [],\n",
       "  'CapAdd': None,\n",
       "  'CapDrop': None,\n",
       "  'Capabilities': None,\n",
       "  'Dns': None,\n",
       "  'DnsOptions': None,\n",
       "  'DnsSearch': None,\n",
       "  'ExtraHosts': None,\n",
       "  'GroupAdd': None,\n",
       "  'IpcMode': 'shareable',\n",
       "  'Cgroup': '',\n",
       "  'Links': None,\n",
       "  'OomScoreAdj': 0,\n",
       "  'PidMode': '',\n",
       "  'Privileged': False,\n",
       "  'PublishAllPorts': False,\n",
       "  'ReadonlyRootfs': False,\n",
       "  'SecurityOpt': None,\n",
       "  'UTSMode': '',\n",
       "  'UsernsMode': '',\n",
       "  'ShmSize': 67108864,\n",
       "  'Runtime': 'runc',\n",
       "  'ConsoleSize': [0, 0],\n",
       "  'Isolation': '',\n",
       "  'CpuShares': 0,\n",
       "  'Memory': 0,\n",
       "  'NanoCpus': 0,\n",
       "  'CgroupParent': '',\n",
       "  'BlkioWeight': 0,\n",
       "  'BlkioWeightDevice': None,\n",
       "  'BlkioDeviceReadBps': None,\n",
       "  'BlkioDeviceWriteBps': None,\n",
       "  'BlkioDeviceReadIOps': None,\n",
       "  'BlkioDeviceWriteIOps': None,\n",
       "  'CpuPeriod': 0,\n",
       "  'CpuQuota': 0,\n",
       "  'CpuRealtimePeriod': 0,\n",
       "  'CpuRealtimeRuntime': 0,\n",
       "  'CpusetCpus': '',\n",
       "  'CpusetMems': '',\n",
       "  'Devices': None,\n",
       "  'DeviceCgroupRules': None,\n",
       "  'DeviceRequests': None,\n",
       "  'KernelMemory': 0,\n",
       "  'KernelMemoryTCP': 0,\n",
       "  'MemoryReservation': 0,\n",
       "  'MemorySwap': 0,\n",
       "  'MemorySwappiness': None,\n",
       "  'OomKillDisable': False,\n",
       "  'PidsLimit': None,\n",
       "  'Ulimits': None,\n",
       "  'CpuCount': 0,\n",
       "  'CpuPercent': 0,\n",
       "  'IOMaximumIOps': 0,\n",
       "  'IOMaximumBandwidth': 0,\n",
       "  'MaskedPaths': ['/proc/asound',\n",
       "   '/proc/acpi',\n",
       "   '/proc/kcore',\n",
       "   '/proc/keys',\n",
       "   '/proc/latency_stats',\n",
       "   '/proc/timer_list',\n",
       "   '/proc/timer_stats',\n",
       "   '/proc/sched_debug',\n",
       "   '/proc/scsi',\n",
       "   '/sys/firmware'],\n",
       "  'ReadonlyPaths': ['/proc/bus',\n",
       "   '/proc/fs',\n",
       "   '/proc/irq',\n",
       "   '/proc/sys',\n",
       "   '/proc/sysrq-trigger']},\n",
       " 'GraphDriver': {'Data': {'LowerDir': '/var/lib/docker/overlay2/e5180b56593469310ccec6c0cd5847af0458db391bf75b5a7c08d65680793fa7-init/diff:/var/lib/docker/overlay2/db6cb3cb307477e87d386136ed4ee66d066bb01e9e221615abb748741229faad/diff:/var/lib/docker/overlay2/0cd268b75c5dc75ae089170df9efe6217768211ae86ef1cf9607cfcaa46d442d/diff:/var/lib/docker/overlay2/760bde377490f794680a0146038c061e1ed49f9cda34143cb8b76c38eb1ed9c9/diff:/var/lib/docker/overlay2/2cd3e9525157340568355f05b12dd564f083800aff829e8b86ab0fa0aa905d71/diff:/var/lib/docker/overlay2/3d93bd3829defba90702fbc7bd8420244dfe47891dfa1b2cb5b3148025830a2a/diff:/var/lib/docker/overlay2/08c63c58670864d561e425cb115d3d82f6ff84badb20b7bc0be8af3854075678/diff:/var/lib/docker/overlay2/b2054ab0700359136e6fdad2b40f5cfe9bd3e6551413d8d7969a52513be746ec/diff:/var/lib/docker/overlay2/c586e2b965938bb2a57d93136261fa07a1cfd8f9168032bf2b11714812901f59/diff:/var/lib/docker/overlay2/9341446373ee3aa11a64f40d6f0155c8ac87bcccfaeccb3c30748fcd8357df19/diff:/var/lib/docker/overlay2/bd05615f0cdf8face1fbec3439d8fffe593f05f5883eba00b19d10cd731756c4/diff:/var/lib/docker/overlay2/1d974d37c7dd7fbcf6f7a9d50f05c2ffc84a78dcfa53f7f518bf5a02972e8bb6/diff:/var/lib/docker/overlay2/6cbb0033a876706d015ec3411fb1584460eb5c77033b4002298560c39e7a8d19/diff:/var/lib/docker/overlay2/a106ca2d53a3dec005fbf412a5bddafd2c17532dcbad46705b3bff8c04fcbb30/diff',\n",
       "   'MergedDir': '/var/lib/docker/overlay2/e5180b56593469310ccec6c0cd5847af0458db391bf75b5a7c08d65680793fa7/merged',\n",
       "   'UpperDir': '/var/lib/docker/overlay2/e5180b56593469310ccec6c0cd5847af0458db391bf75b5a7c08d65680793fa7/diff',\n",
       "   'WorkDir': '/var/lib/docker/overlay2/e5180b56593469310ccec6c0cd5847af0458db391bf75b5a7c08d65680793fa7/work'},\n",
       "  'Name': 'overlay2'},\n",
       " 'Mounts': [{'Type': 'bind',\n",
       "   'Source': '/home/jovyan/data2/db',\n",
       "   'Destination': '/data/db',\n",
       "   'Mode': 'rw',\n",
       "   'RW': True,\n",
       "   'Propagation': 'rprivate'},\n",
       "  {'Type': 'bind',\n",
       "   'Source': '/home/jovyan/data2/configdb',\n",
       "   'Destination': '/data/configdb',\n",
       "   'Mode': 'rw',\n",
       "   'RW': True,\n",
       "   'Propagation': 'rprivate'}],\n",
       " 'Config': {'Hostname': 'mongo2',\n",
       "  'Domainname': '',\n",
       "  'User': '',\n",
       "  'AttachStdin': False,\n",
       "  'AttachStdout': False,\n",
       "  'AttachStderr': False,\n",
       "  'ExposedPorts': {'27017/tcp': {}},\n",
       "  'Tty': False,\n",
       "  'OpenStdin': False,\n",
       "  'StdinOnce': False,\n",
       "  'Env': ['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
       "   'GOSU_VERSION=1.10',\n",
       "   'JSYAML_VERSION=3.10.0',\n",
       "   'GPG_KEYS=9DA31620334BD75D9DCB49F368818C72E52529D4',\n",
       "   'MONGO_PACKAGE=mongodb-org',\n",
       "   'MONGO_REPO=repo.mongodb.org',\n",
       "   'MONGO_MAJOR=4.0',\n",
       "   'MONGO_VERSION=4.0.4'],\n",
       "  'Cmd': None,\n",
       "  'Image': 'mongo:4.0.4',\n",
       "  'Volumes': {'/data/configdb': {}, '/data/db': {}},\n",
       "  'WorkingDir': '',\n",
       "  'Entrypoint': ['/usr/bin/mongod', '--bind_ip_all', '--replSet', 'devrs'],\n",
       "  'OnBuild': None,\n",
       "  'Labels': {'com.docker.compose.config-hash': 'c2d3f586ef641f4db9dc3eacb101ee09ff3c4667a5dac45d95d4452c134f56ec',\n",
       "   'com.docker.compose.container-number': '1',\n",
       "   'com.docker.compose.oneoff': 'False',\n",
       "   'com.docker.compose.project': 'jovyan',\n",
       "   'com.docker.compose.project.config_files': 'docker-compose.yml',\n",
       "   'com.docker.compose.project.working_dir': '/home/jovyan',\n",
       "   'com.docker.compose.service': 'mongo2',\n",
       "   'com.docker.compose.version': '1.25.4'}},\n",
       " 'NetworkSettings': {'Bridge': '',\n",
       "  'SandboxID': '279fc4c019fa3b6b989993c19047563723995181c187a2fb310a9d8896e4708c',\n",
       "  'HairpinMode': False,\n",
       "  'LinkLocalIPv6Address': '',\n",
       "  'LinkLocalIPv6PrefixLen': 0,\n",
       "  'Ports': {'27017/tcp': [{'HostIp': '0.0.0.0', 'HostPort': '30002'}]},\n",
       "  'SandboxKey': '/var/run/docker/netns/279fc4c019fa',\n",
       "  'SecondaryIPAddresses': None,\n",
       "  'SecondaryIPv6Addresses': None,\n",
       "  'EndpointID': '',\n",
       "  'Gateway': '',\n",
       "  'GlobalIPv6Address': '',\n",
       "  'GlobalIPv6PrefixLen': 0,\n",
       "  'IPAddress': '',\n",
       "  'IPPrefixLen': 0,\n",
       "  'IPv6Gateway': '',\n",
       "  'MacAddress': '',\n",
       "  'Networks': {'jovyan_mongo-dev-net': {'IPAMConfig': None,\n",
       "    'Links': None,\n",
       "    'Aliases': ['9d2d38fd4d78', 'mongo2'],\n",
       "    'NetworkID': '9a9b7c872f0b41024fb649179e89bd9bbde3ffbd8de1a7a33f19473f006ad78e',\n",
       "    'EndpointID': 'e8f1e9dfb1b606c3fee87bb0936c29433e5201b98cc0e51a75b65fad46e9dbc4',\n",
       "    'Gateway': '172.19.0.1',\n",
       "    'IPAddress': '172.19.0.3',\n",
       "    'IPPrefixLen': 16,\n",
       "    'IPv6Gateway': '',\n",
       "    'GlobalIPv6Address': '',\n",
       "    'GlobalIPv6PrefixLen': 0,\n",
       "    'MacAddress': '02:42:ac:13:00:03',\n",
       "    'DriverOpts': None}}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container = container_ids[0]\n",
    "\n",
    "client.containers.get(container).attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the local port bound for 27017/tcp for each server in the replica set\n",
    "def get27017tcp_port(c, container):\n",
    "    #cConfig = c.inspect_container(container)\n",
    "    cConfig = client.containers.get(container).attrs\n",
    "    return int(cConfig['NetworkSettings']['Ports']['27017/tcp'][0]['HostPort'])\n",
    "\n",
    "def get27017tcp_ports(c, containers):\n",
    "    ports={}\n",
    "    for _container in containers:\n",
    "        ports[_container.id]= get27017tcp_port(c, _container.id)\n",
    "    return ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30002"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get27017tcp_port(client, container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9d2d38fd4d7816aa0806bd9453525db89992db4bb38c576c9972c0bdebb4be1b': 30002,\n",
       " 'bc2fc497a9f03af1296bb72f94e243fe816984098627e8679e5bbd24193bb3ed': 30001,\n",
       " 'c2e7b1092bbf4b096afb871eb081d8ffbc2fbe97734d59a3970dab3ab962820f': 30003}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "containers = client.containers.list()\n",
    "get27017tcp_ports(client, containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContainIPaddress(c, container, network='jovyan_mongo-dev-net'):\n",
    "    cConfig = client.containers.get(container).attrs\n",
    "    return cConfig['NetworkSettings']['Networks'][network]['IPAddress']\n",
    "\n",
    "def getContainIPaddresses(c, containers):\n",
    "    ipaddresses={}\n",
    "    for _container in containers:\n",
    "        ipaddresses[_container]= getContainIPaddress(c, _container.id)\n",
    "    return ipaddresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172.19.0.3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getContainIPaddress(client, container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<Container: 9d2d38fd4d>: '172.19.0.3',\n",
       " <Container: bc2fc497a9>: '172.19.0.4',\n",
       " <Container: c2e7b1092b>: '172.19.0.2'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getContainIPaddresses(client, containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise the replica set\n",
    "from pymongo import MongoClient\n",
    "\n",
    "#We'll use the 0th server in the set as a root node\n",
    "mc = MongoClient('localhost', get27017tcp_port(client, container))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialise the replica set with a particular configuration, we need to define it using an object that has the following form:\n",
    "\n",
    "```\n",
    "rs_conf = {\"_id\" : \"devrs\",\n",
    "        \"members\" : [{\"_id\" : 1, \"host\" : \"172.19.0.2:30001\"},\n",
    "                     {\"_id\" : 2, \"host\" : \"172.19.0.3:27017\"},\n",
    "                     {\"_id\" : 3, \"host\" : \"172.19.0.4:27017\"} ]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "container2 = container_ids[1]\n",
    "mc2 = MongoClient('localhost', get27017tcp_port(client, container2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_conf = {\"_id\" : \"devrs\",\n",
    "        \"members\" : [{\"_id\" : 1, \"host\" : \"mongo1\"},\n",
    "                     {\"_id\" : 2, \"host\" : \"mongo2\"},\n",
    "                     {\"_id\" : 3, \"host\" : \"mongo3\"} ]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationFailure",
     "evalue": "already initialized, full error: {'operationTime': Timestamp(1604506110, 1), 'ok': 0.0, 'errmsg': 'already initialized', 'code': 23, 'codeName': 'AlreadyInitialized', '$clusterTime': {'clusterTime': Timestamp(1604506110, 1), 'signature': {'hash': b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'keyId': 0}}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationFailure\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-301509498374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Here, we use the replSetInitiate admin command, applying it with the desired configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#mc.admin.command( \"replSetInitiate\", rs_conf);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"replSetInitiate\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# use a default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pymongo/database.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(self, command, value, check, allowable_errors, read_preference, codec_options, session, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m         with self.__client._socket_for_reads(\n\u001b[1;32m    737\u001b[0m                 read_preference, session) as (sock_info, slave_ok):\n\u001b[0;32m--> 738\u001b[0;31m             return self._command(sock_info, command, slave_ok, value,\n\u001b[0m\u001b[1;32m    739\u001b[0m                                  \u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowable_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_preference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                                  codec_options, session=session, **kwargs)\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pymongo/database.py\u001b[0m in \u001b[0;36m_command\u001b[0;34m(self, sock_info, command, slave_ok, value, check, allowable_errors, read_preference, codec_options, write_concern, parse_write_concern_error, session, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tmp_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             return sock_info.command(\n\u001b[0m\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pymongo/pool.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_not_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munacknowledged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             return command(self, dbname, spec, slave_ok,\n\u001b[0m\u001b[1;32m    684\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mongos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_preference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodec_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                            \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowable_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pymongo/network.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(sock_info, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 helpers._check_command_response(\n\u001b[0m\u001b[1;32m    160\u001b[0m                     \u001b[0mresponse_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_wire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                     \u001b[0mallowable_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pymongo/helpers.py\u001b[0m in \u001b[0;36m_check_command_response\u001b[0;34m(response, max_wire_version, msg, allowable_errors, parse_write_concern_error)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             raise OperationFailure(msg % errmsg, code, response,\n\u001b[0m\u001b[1;32m    168\u001b[0m                                    max_wire_version)\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationFailure\u001b[0m: already initialized, full error: {'operationTime': Timestamp(1604506110, 1), 'ok': 0.0, 'errmsg': 'already initialized', 'code': 23, 'codeName': 'AlreadyInitialized', '$clusterTime': {'clusterTime': Timestamp(1604506110, 1), 'signature': {'hash': b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'keyId': 0}}}"
     ]
    }
   ],
   "source": [
    "#In the mongo console, we would typically use the command rs.config() to initial the replica set\n",
    "#Here, we use the replSetInitiate admin command, applying it with the desired configuration\n",
    "mc.admin.command( \"replSetInitiate\", rs_conf);\n",
    "#mc.admin.command( \"replSetInitiate\") # use a default"
   ]
  },
  {
   "source": [
    "Alternatively, if we log in to one of continers eg for `mongo1` (`docker exec -it mongo1 /bin/bash`) and run `mongo` to access the command line, we can then run eg `rs.add('mongo2')`.\n",
    "\n",
    "According to https://stackoverflow.com/a/54758273/454773 we can also do things like the following instead of `rd.add()`:\n",
    "\n",
    "```python\n",
    "import pymongo\n",
    "\n",
    "conn = pymongo.MongoClient()\n",
    "conf = conn.admin.command({'replSetGetConfig': 1})\n",
    "\n",
    "conf['config']['members'].append({\n",
    "    '_id': 3,\n",
    "    'host': 'localhost:27020',\n",
    "    'hidden': True,\n",
    "    'priority': 0})\n",
    "conf['config']['version'] += 1  # Bump the config version\n",
    "\n",
    "res = conn.admin.command({'replSetReconfig': conf['config']})\n",
    "print(res)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'set': 'devrs',\n",
       " 'date': datetime.datetime(2020, 11, 4, 16, 8, 32, 393000),\n",
       " 'myState': 1,\n",
       " 'term': 7,\n",
       " 'syncingTo': '',\n",
       " 'syncSourceHost': '',\n",
       " 'syncSourceId': -1,\n",
       " 'heartbeatIntervalMillis': 2000,\n",
       " 'optimes': {'lastCommittedOpTime': {'ts': Timestamp(1604506110, 1), 't': 7},\n",
       "  'readConcernMajorityOpTime': {'ts': Timestamp(1604506110, 1), 't': 7},\n",
       "  'appliedOpTime': {'ts': Timestamp(1604506110, 1), 't': 7},\n",
       "  'durableOpTime': {'ts': Timestamp(1604506110, 1), 't': 7}},\n",
       " 'lastStableCheckpointTimestamp': Timestamp(1604506071, 1),\n",
       " 'members': [{'_id': 0,\n",
       "   'name': 'mongo2:27017',\n",
       "   'health': 1.0,\n",
       "   'state': 1,\n",
       "   'stateStr': 'PRIMARY',\n",
       "   'uptime': 16,\n",
       "   'optime': {'ts': Timestamp(1604506110, 1), 't': 7},\n",
       "   'optimeDate': datetime.datetime(2020, 11, 4, 16, 8, 30),\n",
       "   'syncingTo': '',\n",
       "   'syncSourceHost': '',\n",
       "   'syncSourceId': -1,\n",
       "   'infoMessage': 'could not find member to sync from',\n",
       "   'electionTime': Timestamp(1604506098, 1),\n",
       "   'electionDate': datetime.datetime(2020, 11, 4, 16, 8, 18),\n",
       "   'configVersion': 1,\n",
       "   'self': True,\n",
       "   'lastHeartbeatMessage': ''}],\n",
       " 'ok': 1.0,\n",
       " 'operationTime': Timestamp(1604506110, 1),\n",
       " '$clusterTime': {'clusterTime': Timestamp(1604506110, 1),\n",
       "  'signature': {'hash': b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n",
       "   'keyId': 0}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We may need to wait a minute or two for the configuration to come up\n",
    "#If you get an error message that suggests the configuration is up yet, wait a few seconds then rerun the cell\n",
    "mc.admin.command('replSetGetStatus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testclient = MongoClient('localhost', get27017tcp_port(client, container))\n",
    "testdb=testclient.testdb\n",
    "testcollection=testdb.testcollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'was': {'verbosity': 0,\n",
       "  'accessControl': {'verbosity': -1},\n",
       "  'command': {'verbosity': -1},\n",
       "  'control': {'verbosity': -1},\n",
       "  'executor': {'verbosity': -1},\n",
       "  'geo': {'verbosity': -1},\n",
       "  'index': {'verbosity': -1},\n",
       "  'network': {'verbosity': -1,\n",
       "   'asio': {'verbosity': -1},\n",
       "   'bridge': {'verbosity': -1}},\n",
       "  'query': {'verbosity': -1},\n",
       "  'replication': {'verbosity': -1,\n",
       "   'heartbeats': {'verbosity': -1},\n",
       "   'rollback': {'verbosity': -1}},\n",
       "  'sharding': {'verbosity': -1, 'shardingCatalogRefresh': {'verbosity': -1}},\n",
       "  'storage': {'verbosity': -1,\n",
       "   'recovery': {'verbosity': -1},\n",
       "   'journal': {'verbosity': -1}},\n",
       "  'write': {'verbosity': -1},\n",
       "  'ftdc': {'verbosity': -1},\n",
       "  'tracking': {'verbosity': -1},\n",
       "  'transaction': {'verbosity': -1}},\n",
       " 'ok': 1.0,\n",
       " 'operationTime': Timestamp(1604507020, 1),\n",
       " '$clusterTime': {'clusterTime': Timestamp(1604507020, 1),\n",
       "  'signature': {'hash': b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n",
       "   'keyId': 0}}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/42632816/pymongo-set-log-level\n",
    "from bson import SON\n",
    "\n",
    "mc.admin.command(SON([\n",
    "    (\"setParameter\", 1),\n",
    "    (\"logComponentVerbosity\", {\n",
    "        \"storage\": {\n",
    "            \"verbosity\": 5,\n",
    "            \"journal\": {\n",
    "                \"verbosity\": 1\n",
    "            }\n",
    "        }\n",
    "    })]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7f51d386ae80>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testcollection.insert_one({'name':'test1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,10):\n",
    "    testcollection.insert_one({'name':'test'+str(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5fa2c9266dd0e7f5ad614b66'), 'name': 'test1'}\n",
      "{'_id': ObjectId('5fa2c94f6dd0e7f5ad614b67'), 'name': 'test0'}\n",
      "{'_id': ObjectId('5fa2c94f6dd0e7f5ad614b68'), 'name': 'test1'}\n",
      "{'_id': ObjectId('5fa2c94f6dd0e7f5ad614b69'), 'name': 'test2'}\n",
      "{'_id': ObjectId('5fa2c9506dd0e7f5ad614b6a'), 'name': 'test3'}\n",
      "{'_id': ObjectId('5fa2c9506dd0e7f5ad614b6b'), 'name': 'test4'}\n",
      "{'_id': ObjectId('5fa2c9506dd0e7f5ad614b6c'), 'name': 'test5'}\n",
      "{'_id': ObjectId('5fa2c9506dd0e7f5ad614b6d'), 'name': 'test6'}\n",
      "{'_id': ObjectId('5fa2c9506dd0e7f5ad614b6e'), 'name': 'test7'}\n",
      "{'_id': ObjectId('5fa2c9506dd0e7f5ad614b6f'), 'name': 'test8'}\n",
      "{'_id': ObjectId('5fa2c9506dd0e7f5ad614b70'), 'name': 'test9'}\n",
      "{'_id': ObjectId('5fa2c9546dd0e7f5ad614b71'), 'name': 'test0'}\n",
      "{'_id': ObjectId('5fa2c9546dd0e7f5ad614b72'), 'name': 'test1'}\n",
      "{'_id': ObjectId('5fa2c9546dd0e7f5ad614b73'), 'name': 'test2'}\n",
      "{'_id': ObjectId('5fa2c9546dd0e7f5ad614b74'), 'name': 'test3'}\n",
      "{'_id': ObjectId('5fa2c9546dd0e7f5ad614b75'), 'name': 'test4'}\n",
      "{'_id': ObjectId('5fa2c9546dd0e7f5ad614b76'), 'name': 'test5'}\n",
      "{'_id': ObjectId('5fa2c9546dd0e7f5ad614b77'), 'name': 'test6'}\n",
      "{'_id': ObjectId('5fa2c9546dd0e7f5ad614b78'), 'name': 'test7'}\n",
      "{'_id': ObjectId('5fa2c9546dd0e7f5ad614b79'), 'name': 'test8'}\n",
      "{'_id': ObjectId('5fa2c9546dd0e7f5ad614b7a'), 'name': 'test9'}\n",
      "{'_id': ObjectId('5fa2d20c86ce529906817525'), 'name': 'test1'}\n",
      "{'_id': ObjectId('5fa2d20d86ce529906817526'), 'name': 'test0'}\n",
      "{'_id': ObjectId('5fa2d20d86ce529906817527'), 'name': 'test1'}\n",
      "{'_id': ObjectId('5fa2d20d86ce529906817528'), 'name': 'test2'}\n",
      "{'_id': ObjectId('5fa2d20d86ce529906817529'), 'name': 'test3'}\n",
      "{'_id': ObjectId('5fa2d20d86ce52990681752a'), 'name': 'test4'}\n",
      "{'_id': ObjectId('5fa2d20d86ce52990681752b'), 'name': 'test5'}\n",
      "{'_id': ObjectId('5fa2d20d86ce52990681752c'), 'name': 'test6'}\n",
      "{'_id': ObjectId('5fa2d20d86ce52990681752d'), 'name': 'test7'}\n",
      "{'_id': ObjectId('5fa2d20d86ce52990681752e'), 'name': 'test8'}\n",
      "{'_id': ObjectId('5fa2d20d86ce52990681752f'), 'name': 'test9'}\n"
     ]
    }
   ],
   "source": [
    "for ff in testcollection.find():\n",
    "    print(ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can model network failures by setting up firewall rules to block messages being passed between particular containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://github.com/dcm-oss/blockade/\n",
    "\n",
    "#\n",
    "#  Copyright (C) 2014 Dell, Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "\n",
    "import random\n",
    "import string\n",
    "import subprocess\n",
    "\n",
    "import collections.abc\n",
    "\n",
    "\n",
    "#---errors.py\n",
    "class BlockadeError(Exception):\n",
    "    \"\"\"Expected error within Blockade\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class BlockadeConfigError(BlockadeError):\n",
    "    \"\"\"Error in configuration\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class AlreadyInitializedError(BlockadeError):\n",
    "    \"\"\"Blockade already created in this context\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class NotInitializedError(BlockadeError):\n",
    "    \"\"\"Blockade not created in this context\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class InconsistentStateError(BlockadeError):\n",
    "    \"\"\"Blockade state is inconsistent (partially created or destroyed)\n",
    "    \"\"\"\n",
    "    \n",
    "#---\n",
    "\n",
    "\n",
    "\n",
    "def parse_partition_index(blockade_id, chain):\n",
    "    prefix = \"%s-p\" % (blockade_id,)\n",
    "    if chain and chain.startswith(prefix):\n",
    "        try:\n",
    "            return int(chain[len(prefix):])\n",
    "        except ValueError:\n",
    "            pass\n",
    "    raise ValueError(\"chain %s is not a blockade partition\" % (chain,))\n",
    "\n",
    "\n",
    "def partition_chain_name(blockade_id, partition_index):\n",
    "    return \"%s-p%s\" % (blockade_id, partition_index)\n",
    "\n",
    "\n",
    "def iptables_call_output(*args):\n",
    "    cmd = [\"iptables\", \"-n\"] + list(args)\n",
    "    try:\n",
    "        output = subprocess.check_output(cmd)\n",
    "        return output.decode().split(\"\\n\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        raise BlockadeError(\"Problem calling '%s'\" % \" \".join(cmd))\n",
    "\n",
    "\n",
    "def iptables_call(*args):\n",
    "    cmd = [\"iptables\"] + list(args)\n",
    "    try:\n",
    "        subprocess.check_call(cmd)\n",
    "    except subprocess.CalledProcessError:\n",
    "        raise BlockadeError(\"Problem calling '%s'\" % \" \".join(cmd))\n",
    "\n",
    "\n",
    "def iptables_get_chain_rules(chain):\n",
    "    if not chain:\n",
    "        raise ValueError(\"invalid chain\")\n",
    "    lines = iptables_call_output(\"-L\", chain)\n",
    "    if len(lines) < 2:\n",
    "        raise BlockadeError(\"Can't understand iptables output: \\n%s\" %\n",
    "                            \"\\n\".join(lines))\n",
    "\n",
    "    chain_line, header_line = lines[:2]\n",
    "    if not (chain_line.startswith(\"Chain \" + chain) and\n",
    "            header_line.startswith(\"target\")):\n",
    "        raise BlockadeError(\"Can't understand iptables output: \\n%s\" %\n",
    "                            \"\\n\".join(lines))\n",
    "    return lines[2:]\n",
    "\n",
    "\n",
    "def iptables_get_source_chains(blockade_id):\n",
    "    \"\"\"Get a map of blockade chains IDs -> list of IPs targeted at them\n",
    "\n",
    "    For figuring out which container is in which partition\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    if not blockade_id:\n",
    "        raise ValueError(\"invalid blockade_id\")\n",
    "    lines = iptables_get_chain_rules(\"FORWARD\")\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        try:\n",
    "            partition_index = parse_partition_index(blockade_id, parts[0])\n",
    "        except ValueError:\n",
    "            continue  # not a rule targetting a blockade chain\n",
    "\n",
    "        source = parts[3]\n",
    "        if source:\n",
    "            result[source] = partition_index\n",
    "    return result\n",
    "\n",
    "\n",
    "def iptables_delete_rules(chain, predicate):\n",
    "    if not chain:\n",
    "        raise ValueError(\"invalid chain\")\n",
    "    if not isinstance(predicate, collections.Callable):\n",
    "        raise ValueError(\"invalid predicate\")\n",
    "\n",
    "    lines = iptables_get_chain_rules(chain)\n",
    "\n",
    "    # TODO this is susceptible to check-then-act races.\n",
    "    # better to ultimately switch to python-iptables if it becomes less buggy\n",
    "    for index, line in reversed(list(enumerate(lines, 1))):\n",
    "        line = line.strip()\n",
    "        if line and predicate(line):\n",
    "            iptables_call(\"-D\", chain, str(index))\n",
    "\n",
    "\n",
    "def iptables_delete_blockade_rules(blockade_id):\n",
    "    def predicate(rule):\n",
    "        target = rule.split()[0]\n",
    "        try:\n",
    "            parse_partition_index(blockade_id, target)\n",
    "        except ValueError:\n",
    "            return False\n",
    "        return True\n",
    "    iptables_delete_rules(\"FORWARD\", predicate)\n",
    "\n",
    "\n",
    "def iptables_delete_blockade_chains(blockade_id):\n",
    "    if not blockade_id:\n",
    "        raise ValueError(\"invalid blockade_id\")\n",
    "\n",
    "    lines = iptables_call_output(\"-L\")\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 2 and parts[0] == \"Chain\":\n",
    "            chain = parts[1]\n",
    "            try:\n",
    "                parse_partition_index(blockade_id, chain)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            # if we are a valid blockade chain, flush and delete\n",
    "            iptables_call(\"-F\", chain)\n",
    "            iptables_call(\"-X\", chain)\n",
    "\n",
    "\n",
    "def iptables_insert_rule(chain, src=None, dest=None, target=None):\n",
    "    \"\"\"Insert a new rule in the chain\n",
    "    \"\"\"\n",
    "    if not chain:\n",
    "        raise ValueError(\"Invalid chain\")\n",
    "    if not target:\n",
    "        raise ValueError(\"Invalid target\")\n",
    "    if not (src or dest):\n",
    "        raise ValueError(\"Need src, dest, or both\")\n",
    "\n",
    "    args = [\"-I\", chain]\n",
    "    if src:\n",
    "        args += [\"-s\", src]\n",
    "    if dest:\n",
    "        args += [\"-d\", dest]\n",
    "    args += [\"-j\", target]\n",
    "    iptables_call(*args)\n",
    "\n",
    "\n",
    "def iptables_create_chain(chain):\n",
    "    \"\"\"Create a new chain\n",
    "    \"\"\"\n",
    "    if not chain:\n",
    "        raise ValueError(\"Invalid chain\")\n",
    "    iptables_call(\"-N\", chain)\n",
    "\n",
    "\n",
    "def clear_iptables(blockade_id):\n",
    "    \"\"\"Remove all iptables rules and chains related to this blockade\n",
    "    \"\"\"\n",
    "    # first remove refererences to our custom chains\n",
    "    iptables_delete_blockade_rules(blockade_id)\n",
    "\n",
    "    # then remove the chains themselves\n",
    "    iptables_delete_blockade_chains(blockade_id)\n",
    "\n",
    "\n",
    "def partition_containers(blockade_id, partitions):\n",
    "    if not partitions or len(partitions) == 1:\n",
    "        return\n",
    "    for index, partition in enumerate(partitions, 1):\n",
    "        chain_name = partition_chain_name(blockade_id, index)\n",
    "\n",
    "        # create chain for partition and block traffic TO any other partition\n",
    "        iptables_create_chain(chain_name)\n",
    "        for other in partitions:\n",
    "            if partition is other:\n",
    "                continue\n",
    "            for container in other:\n",
    "                if container.ip_address:\n",
    "                    iptables_insert_rule(chain_name, dest=container.ip_address,\n",
    "                                         target=\"DROP\")\n",
    "\n",
    "        # direct traffic FROM any container in the partition to the new chain\n",
    "        for container in partition:\n",
    "            iptables_insert_rule(\"FORWARD\", src=container.ip_address,\n",
    "                                 target=chain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class netobj():\n",
    "    def __init__(self, ip_address):\n",
    "        self.ip_address = ip_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign the IP addresses of the containers into different partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this case, let's be cruel and put the primary in a partition on its own\n",
    "partition_containers('test1w2s5', [ [netobj('172.19.0.2')],[netobj('172.19.0.3'),netobj('172.19.0.4')]])\n",
    "#Wait a bit before generating the log..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'set': 'devrs',\n",
       " 'date': datetime.datetime(2020, 11, 4, 16, 30, 5, 970000),\n",
       " 'myState': 1,\n",
       " 'term': 7,\n",
       " 'syncingTo': '',\n",
       " 'syncSourceHost': '',\n",
       " 'syncSourceId': -1,\n",
       " 'heartbeatIntervalMillis': 2000,\n",
       " 'optimes': {'lastCommittedOpTime': {'ts': Timestamp(1604507400, 1), 't': 7},\n",
       "  'readConcernMajorityOpTime': {'ts': Timestamp(1604507400, 1), 't': 7},\n",
       "  'appliedOpTime': {'ts': Timestamp(1604507400, 1), 't': 7},\n",
       "  'durableOpTime': {'ts': Timestamp(1604507400, 1), 't': 7}},\n",
       " 'lastStableCheckpointTimestamp': Timestamp(1604507350, 1),\n",
       " 'members': [{'_id': 0,\n",
       "   'name': 'mongo2:27017',\n",
       "   'health': 1.0,\n",
       "   'state': 1,\n",
       "   'stateStr': 'PRIMARY',\n",
       "   'uptime': 1309,\n",
       "   'optime': {'ts': Timestamp(1604507400, 1), 't': 7},\n",
       "   'optimeDate': datetime.datetime(2020, 11, 4, 16, 30),\n",
       "   'syncingTo': '',\n",
       "   'syncSourceHost': '',\n",
       "   'syncSourceId': -1,\n",
       "   'infoMessage': '',\n",
       "   'electionTime': Timestamp(1604506098, 1),\n",
       "   'electionDate': datetime.datetime(2020, 11, 4, 16, 8, 18),\n",
       "   'configVersion': 1,\n",
       "   'self': True,\n",
       "   'lastHeartbeatMessage': ''}],\n",
       " 'ok': 1.0,\n",
       " 'operationTime': Timestamp(1604507400, 1),\n",
       " '$clusterTime': {'clusterTime': Timestamp(1604507400, 1),\n",
       "  'signature': {'hash': b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n",
       "   'keyId': 0}}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.admin.command('replSetGetStatus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationFailure",
     "evalue": "no such command: 'printSlaveReplicationInfo', full error: {'operationTime': Timestamp(1604507560, 1), 'ok': 0.0, 'errmsg': \"no such command: 'printSlaveReplicationInfo'\", 'code': 59, 'codeName': 'CommandNotFound', '$clusterTime': {'clusterTime': Timestamp(1604507560, 1), 'signature': {'hash': b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'keyId': 0}}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationFailure\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-bfacbf79ffcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'printSlaveReplicationInfo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pymongo/database.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(self, command, value, check, allowable_errors, read_preference, codec_options, session, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m         with self.__client._socket_for_reads(\n\u001b[1;32m    737\u001b[0m                 read_preference, session) as (sock_info, slave_ok):\n\u001b[0;32m--> 738\u001b[0;31m             return self._command(sock_info, command, slave_ok, value,\n\u001b[0m\u001b[1;32m    739\u001b[0m                                  \u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowable_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_preference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                                  codec_options, session=session, **kwargs)\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pymongo/database.py\u001b[0m in \u001b[0;36m_command\u001b[0;34m(self, sock_info, command, slave_ok, value, check, allowable_errors, read_preference, codec_options, write_concern, parse_write_concern_error, session, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tmp_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             return sock_info.command(\n\u001b[0m\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pymongo/pool.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_not_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munacknowledged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             return command(self, dbname, spec, slave_ok,\n\u001b[0m\u001b[1;32m    684\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mongos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_preference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodec_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                            \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowable_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pymongo/network.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(sock_info, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 helpers._check_command_response(\n\u001b[0m\u001b[1;32m    160\u001b[0m                     \u001b[0mresponse_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_wire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                     \u001b[0mallowable_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pymongo/helpers.py\u001b[0m in \u001b[0;36m_check_command_response\u001b[0;34m(response, max_wire_version, msg, allowable_errors, parse_write_concern_error)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             raise OperationFailure(msg % errmsg, code, response,\n\u001b[0m\u001b[1;32m    168\u001b[0m                                    max_wire_version)\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationFailure\u001b[0m: no such command: 'printSlaveReplicationInfo', full error: {'operationTime': Timestamp(1604507560, 1), 'ok': 0.0, 'errmsg': \"no such command: 'printSlaveReplicationInfo'\", 'code': 59, 'codeName': 'CommandNotFound', '$clusterTime': {'clusterTime': Timestamp(1604507560, 1), 'signature': {'hash': b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00', 'keyId': 0}}}"
     ]
    }
   ],
   "source": [
    "mc.admin.command('printSlaveReplicationInfo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                      NAMES\r\n",
      "9d2d38fd4d78        mongo:4.0.4         \"/usr/bin/mongod --b\"   16 minutes ago      Up 16 minutes       0.0.0.0:30002->27017/tcp   mongo2\r\n",
      "bc2fc497a9f0        mongo:4.0.4         \"/usr/bin/mongod --b\"   16 minutes ago      Up 16 minutes       0.0.0.0:30001->27017/tcp   mongo1\r\n",
      "c2e7b1092bbf        mongo:4.0.4         \"/usr/bin/mongod --b\"   16 minutes ago      Up 16 minutes       0.0.0.0:30003->27017/tcp   mongo3\r\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker logs mongo1 > mongo1.txt\n",
    "!docker logs mongo2 > mongo2.txt\n",
    "!docker logs mongo3 > mongo3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-04T16:08:17.034+0000 I CONTROL  [initandlisten]     target_arch: x86_64\r\n",
      "2020-11-04T16:08:17.034+0000 I CONTROL  [initandlisten] options: { net: { bindIpAll: true }, replication: { replSet: \"devrs\" } }\r\n",
      "2020-11-04T16:08:17.035+0000 W STORAGE  [initandlisten] Detected unclean shutdown - /data/db/mongod.lock is not empty.\r\n",
      "2020-11-04T16:08:17.036+0000 I STORAGE  [initandlisten] Detected data files in /data/db created by the 'wiredTiger' storage engine, so setting the active storage engine to 'wiredTiger'.\r\n",
      "2020-11-04T16:08:17.037+0000 W STORAGE  [initandlisten] Recovering data from the last clean checkpoint.\r\n",
      "2020-11-04T16:08:17.037+0000 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=984M,session_max=20000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),statistics_log=(wait=0),verbose=(recovery_progress),\r\n",
      "2020-11-04T16:08:17.886+0000 I STORAGE  [initandlisten] WiredTiger message [1604506097:886059][1:0x7fbbb7cd1a40], txn-recover: Main recovery loop: starting at 6/5632 to 7/256\r\n",
      "2020-11-04T16:08:17.888+0000 I STORAGE  [initandlisten] WiredTiger message [1604506097:888011][1:0x7fbbb7cd1a40], txn-recover: Recovering log 6 through 7\r\n",
      "2020-11-04T16:08:18.025+0000 I STORAGE  [initandlisten] WiredTiger message [1604506098:25263][1:0x7fbbb7cd1a40], txn-recover: Recovering log 7 through 7\r\n",
      "2020-11-04T16:08:18.096+0000 I STORAGE  [initandlisten] WiredTiger message [1604506098:96715][1:0x7fbbb7cd1a40], txn-recover: Set global recovery timestamp: 0\r\n",
      "2020-11-04T16:08:18.118+0000 I RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)\r\n",
      "2020-11-04T16:08:18.153+0000 I CONTROL  [initandlisten] \r\n",
      "2020-11-04T16:08:18.153+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.\r\n",
      "2020-11-04T16:08:18.153+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.\r\n",
      "2020-11-04T16:08:18.153+0000 I CONTROL  [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.\r\n",
      "2020-11-04T16:08:18.153+0000 I CONTROL  [initandlisten] \r\n",
      "2020-11-04T16:08:18.179+0000 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/db/diagnostic.data'\r\n",
      "2020-11-04T16:08:18.181+0000 I REPL     [initandlisten] Did not find local voted for document at startup.\r\n",
      "2020-11-04T16:08:18.181+0000 I REPL     [initandlisten] Rollback ID is 1\r\n",
      "2020-11-04T16:08:18.181+0000 I REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset\r\n",
      "2020-11-04T16:08:18.182+0000 I NETWORK  [initandlisten] waiting for connections on port 27017\r\n",
      "2020-11-04T16:08:18.182+0000 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Replication has not yet been configured\r\n",
      "2020-11-04T16:08:18.182+0000 I CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: config.system.sessions does not exist\r\n",
      "2020-11-04T16:08:19.015+0000 I FTDC     [ftdc] Unclean full-time diagnostic data capture shutdown detected, found interim file, some metrics may have been lost. OK\r\n",
      "2020-11-04T16:13:18.182+0000 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Replication has not yet been configured\r\n",
      "2020-11-04T16:13:18.182+0000 I CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: config.system.sessions does not exist\r\n",
      "2020-11-04T16:18:18.184+0000 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Replication has not yet been configured\r\n",
      "2020-11-04T16:18:18.184+0000 I CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: config.system.sessions does not exist\r\n",
      "2020-11-04T16:23:18.184+0000 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Replication has not yet been configured\r\n",
      "2020-11-04T16:23:18.185+0000 I CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: config.system.sessions does not exist\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 30 mongo1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-04T16:24:26.854+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:26.955+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:27.000+0000 D STORAGE  [ftdc] setting timestamp read source: 1, provided timestamp: none\r\n",
      "2020-11-04T16:24:27.001+0000 D STORAGE  [ftdc] NamespaceUUIDCache: registered namespace local.oplog.rs with UUID 953dc1ca-6a48-4ca2-ada0-020dafcc68b0\r\n",
      "2020-11-04T16:24:27.017+0000 D STORAGE  [rsSync-0] NamespaceUUIDCache: registered namespace local.replset.minvalid with UUID 0eb68e90-6a8d-4f73-9f9d-e796e743c141\r\n",
      "2020-11-04T16:24:27.017+0000 D STORAGE  [rsSync-0] WT begin_transaction for snapshot id 4694\r\n",
      "2020-11-04T16:24:27.017+0000 D STORAGE  [rsSync-0] WT rollback_transaction for snapshot id 4694\r\n",
      "2020-11-04T16:24:27.055+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:27.156+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:27.257+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:27.358+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:27.458+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:27.559+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:27.659+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:27.760+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:27.860+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:27.961+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:28.000+0000 D STORAGE  [ftdc] setting timestamp read source: 1, provided timestamp: none\r\n",
      "2020-11-04T16:24:28.001+0000 D STORAGE  [ftdc] NamespaceUUIDCache: registered namespace local.oplog.rs with UUID 953dc1ca-6a48-4ca2-ada0-020dafcc68b0\r\n",
      "2020-11-04T16:24:28.018+0000 D STORAGE  [rsSync-0] NamespaceUUIDCache: registered namespace local.replset.minvalid with UUID 0eb68e90-6a8d-4f73-9f9d-e796e743c141\r\n",
      "2020-11-04T16:24:28.018+0000 D STORAGE  [rsSync-0] WT begin_transaction for snapshot id 4698\r\n",
      "2020-11-04T16:24:28.018+0000 D STORAGE  [rsSync-0] WT rollback_transaction for snapshot id 4698\r\n",
      "2020-11-04T16:24:28.061+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:28.162+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:28.263+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:28.365+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:28.469+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:28.572+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:28.676+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:28.777+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:28.878+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:28.980+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:29.000+0000 D STORAGE  [ftdc] setting timestamp read source: 1, provided timestamp: none\r\n",
      "2020-11-04T16:24:29.001+0000 D STORAGE  [ftdc] NamespaceUUIDCache: registered namespace local.oplog.rs with UUID 953dc1ca-6a48-4ca2-ada0-020dafcc68b0\r\n",
      "2020-11-04T16:24:29.019+0000 D STORAGE  [rsSync-0] NamespaceUUIDCache: registered namespace local.replset.minvalid with UUID 0eb68e90-6a8d-4f73-9f9d-e796e743c141\r\n",
      "2020-11-04T16:24:29.019+0000 D STORAGE  [rsSync-0] WT begin_transaction for snapshot id 4702\r\n",
      "2020-11-04T16:24:29.019+0000 D STORAGE  [rsSync-0] WT rollback_transaction for snapshot id 4702\r\n",
      "2020-11-04T16:24:29.081+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:29.184+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:29.286+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:29.387+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace testdb.testcollection with UUID b148d0c1-aeca-4ee2-8ed3-0d0cca3b2c24\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace local.system.rollback.id with UUID a8e38073-2b5d-453d-bfba-c714332af947\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace config.transactions with UUID 0d7217da-c1a3-4a88-98c2-7a92876fdf1f\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace config.system.sessions with UUID 952f6f5b-254d-43f5-b491-c7cabb676eee\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace admin.system.version with UUID 8217fef4-b7a1-4685-aef3-7cad811c9218\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace admin.system.keys with UUID 72348ace-c021-4b9e-93dd-2fe6d96f7bd9\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace local.oplog.rs with UUID 953dc1ca-6a48-4ca2-ada0-020dafcc68b0\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace local.replset.election with UUID d00a0646-3c17-4a5b-80d0-7238b31bd006\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace local.replset.minvalid with UUID 0eb68e90-6a8d-4f73-9f9d-e796e743c141\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace local.replset.oplogTruncateAfterPoint with UUID 2395d53f-e3ac-482e-891d-f2a08e106e8f\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace local.startup_log with UUID 761cda29-b8d7-45e1-9a85-1ed540fbc454\r\n",
      "2020-11-04T16:24:29.460+0000 D STORAGE  [clientcursormon] NamespaceUUIDCache: registered namespace local.system.replset with UUID 30711a44-7df9-418b-84f1-7c025f8abf3d\r\n",
      "2020-11-04T16:24:29.487+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:29.589+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:29.689+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:29.790+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:29.891+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:29.991+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:30.000+0000 D STORAGE  [ftdc] setting timestamp read source: 1, provided timestamp: none\r\n",
      "2020-11-04T16:24:30.001+0000 D STORAGE  [ftdc] NamespaceUUIDCache: registered namespace local.oplog.rs with UUID 953dc1ca-6a48-4ca2-ada0-020dafcc68b0\r\n",
      "2020-11-04T16:24:30.020+0000 D STORAGE  [rsSync-0] NamespaceUUIDCache: registered namespace local.replset.minvalid with UUID 0eb68e90-6a8d-4f73-9f9d-e796e743c141\r\n",
      "2020-11-04T16:24:30.020+0000 D STORAGE  [rsSync-0] WT begin_transaction for snapshot id 4707\r\n",
      "2020-11-04T16:24:30.021+0000 D STORAGE  [rsSync-0] WT rollback_transaction for snapshot id 4707\r\n",
      "2020-11-04T16:24:30.092+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:30.194+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:30.294+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:30.325+0000 D STORAGE  [NoopWriter] WT begin_transaction for snapshot id 4663\r\n",
      "2020-11-04T16:24:30.325+0000 D STORAGE  [NoopWriter] WT set timestamp of future write operations to Timestamp(1604507070, 1)\r\n",
      "2020-11-04T16:24:30.325+0000 D STORAGE  [NoopWriter] inserting record with timestamp Timestamp(1604507070, 1)\r\n",
      "2020-11-04T16:24:30.325+0000 D STORAGE  [NoopWriter] WT set timestamp of future write operations to Timestamp(1604507070, 1)\r\n",
      "2020-11-04T16:24:30.325+0000 D STORAGE  [NoopWriter] WT commit_transaction for snapshot id 4663\r\n",
      "2020-11-04T16:24:30.396+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:30.396+0000 D STORAGE  [WTJournalFlusher] oldest_timestamp set to Timestamp(1604507060, 1)\r\n",
      "2020-11-04T16:24:30.424+0000 D STORAGE  [WTOplogJournalThread] flushed journal\r\n",
      "2020-11-04T16:24:30.424+0000 D STORAGE  [WTOplogJournalThread] setting new oplogReadTimestamp: 6891305391850782721\r\n",
      "2020-11-04T16:24:30.496+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:30.597+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:30.697+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n",
      "2020-11-04T16:24:30.798+0000 D STORAGE  [WTJournalFlusher] flushed journal\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 80 mongo2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-04T16:08:18.124+0000 I REPL     [replexec-0] New replica set config in use: { _id: \"devrs\", version: 1, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: \"mongo3:27017\", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5fa2cedecda5066af5fece76') } }\r\n",
      "2020-11-04T16:08:18.125+0000 I REPL     [replexec-0] This node is mongo3:27017 in the config\r\n",
      "2020-11-04T16:08:18.125+0000 I REPL     [replexec-0] transition to STARTUP2 from STARTUP\r\n",
      "2020-11-04T16:08:18.125+0000 I REPL     [replexec-0] Starting replication storage threads\r\n",
      "2020-11-04T16:08:18.126+0000 I NETWORK  [LogicalSessionCacheRefresh] Starting new replica set monitor for devrs/mongo3:27017\r\n",
      "2020-11-04T16:08:18.126+0000 I NETWORK  [listener] connection accepted from 172.19.0.2:47510 #2 (1 connection now open)\r\n",
      "2020-11-04T16:08:18.127+0000 I NETWORK  [conn2] received client metadata from 172.19.0.2:47510 conn2: { driver: { name: \"MongoDB Internal Client\", version: \"4.0.4\" }, os: { type: \"Linux\", name: \"Ubuntu\", architecture: \"x86_64\", version: \"16.04\" } }\r\n",
      "2020-11-04T16:08:18.127+0000 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Successfully connected to mongo3:27017 (1 connections now open to mongo3:27017 with a 5 second timeout)\r\n",
      "2020-11-04T16:08:18.127+0000 W NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set devrs\r\n",
      "2020-11-04T16:08:18.128+0000 I REPL     [replexec-0] transition to RECOVERING from STARTUP2\r\n",
      "2020-11-04T16:08:18.129+0000 I REPL     [replexec-0] Starting replication fetcher thread\r\n",
      "2020-11-04T16:08:18.129+0000 I REPL     [replexec-0] Starting replication applier thread\r\n",
      "2020-11-04T16:08:18.129+0000 I REPL     [rsSync-0] Starting oplog application\r\n",
      "2020-11-04T16:08:18.129+0000 I REPL     [rsSync-0] transition to SECONDARY from RECOVERING\r\n",
      "2020-11-04T16:08:18.130+0000 I REPL     [rsSync-0] conducting a dry run election to see if we could be elected. current term: 3\r\n",
      "2020-11-04T16:08:18.129+0000 I REPL     [replexec-0] Starting replication reporter thread\r\n",
      "2020-11-04T16:08:18.130+0000 I REPL     [replexec-1] dry election run succeeded, running for election in term 4\r\n",
      "2020-11-04T16:08:18.132+0000 I REPL     [replexec-0] election succeeded, assuming primary role in term 4\r\n",
      "2020-11-04T16:08:18.132+0000 I REPL     [replexec-0] transition to PRIMARY from SECONDARY\r\n",
      "2020-11-04T16:08:18.132+0000 I REPL     [replexec-0] Resetting sync source to empty, which was :27017\r\n",
      "2020-11-04T16:08:18.133+0000 I REPL     [replexec-0] Entering primary catch-up mode.\r\n",
      "2020-11-04T16:08:18.133+0000 I REPL     [replexec-0] Exited primary catch-up mode.\r\n",
      "2020-11-04T16:08:18.133+0000 I REPL     [replexec-0] Stopping replication producer\r\n",
      "2020-11-04T16:08:18.629+0000 W NETWORK  [LogicalSessionCacheRefresh] Unable to reach primary for set devrs\r\n",
      "2020-11-04T16:08:19.130+0000 W NETWORK  [LogicalSessionCacheRefresh] Unable to reach primary for set devrs\r\n",
      "2020-11-04T16:08:19.633+0000 W NETWORK  [LogicalSessionCacheRefresh] Unable to reach primary for set devrs\r\n",
      "2020-11-04T16:08:20.131+0000 I REPL     [rsSync-0] transition to primary complete; database writes are now permitted\r\n",
      "2020-11-04T16:08:20.135+0000 I NETWORK  [listener] connection accepted from 172.19.0.2:47512 #4 (2 connections now open)\r\n",
      "2020-11-04T16:08:20.135+0000 I NETWORK  [conn4] received client metadata from 172.19.0.2:47512 conn4: { driver: { name: \"MongoDB Internal Client\", version: \"4.0.4\" }, os: { type: \"Linux\", name: \"Ubuntu\", architecture: \"x86_64\", version: \"16.04\" } }\r\n",
      "2020-11-04T16:08:20.136+0000 I NETWORK  [LogicalSessionCacheRefresh] Successfully connected to mongo3:27017 (1 connections now open to mongo3:27017 with a 0 second timeout)\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 30 mongo3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_iptables('test1w2s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker logs mongo1 > mongo1.txt\n",
    "!docker logs mongo2 > mongo2.txt\n",
    "!docker logs mongo3 > mongo3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-04T16:08:17.034+0000 I CONTROL  [initandlisten] modules: none\r\n",
      "2020-11-04T16:08:17.034+0000 I CONTROL  [initandlisten] build environment:\r\n",
      "2020-11-04T16:08:17.034+0000 I CONTROL  [initandlisten]     distmod: ubuntu1604\r\n",
      "2020-11-04T16:08:17.034+0000 I CONTROL  [initandlisten]     distarch: x86_64\r\n",
      "2020-11-04T16:08:17.034+0000 I CONTROL  [initandlisten]     target_arch: x86_64\r\n",
      "2020-11-04T16:08:17.034+0000 I CONTROL  [initandlisten] options: { net: { bindIpAll: true }, replication: { replSet: \"devrs\" } }\r\n",
      "2020-11-04T16:08:17.035+0000 W STORAGE  [initandlisten] Detected unclean shutdown - /data/db/mongod.lock is not empty.\r\n",
      "2020-11-04T16:08:17.036+0000 I STORAGE  [initandlisten] Detected data files in /data/db created by the 'wiredTiger' storage engine, so setting the active storage engine to 'wiredTiger'.\r\n",
      "2020-11-04T16:08:17.037+0000 W STORAGE  [initandlisten] Recovering data from the last clean checkpoint.\r\n",
      "2020-11-04T16:08:17.037+0000 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=984M,session_max=20000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),statistics_log=(wait=0),verbose=(recovery_progress),\r\n",
      "2020-11-04T16:08:17.886+0000 I STORAGE  [initandlisten] WiredTiger message [1604506097:886059][1:0x7fbbb7cd1a40], txn-recover: Main recovery loop: starting at 6/5632 to 7/256\r\n",
      "2020-11-04T16:08:17.888+0000 I STORAGE  [initandlisten] WiredTiger message [1604506097:888011][1:0x7fbbb7cd1a40], txn-recover: Recovering log 6 through 7\r\n",
      "2020-11-04T16:08:18.025+0000 I STORAGE  [initandlisten] WiredTiger message [1604506098:25263][1:0x7fbbb7cd1a40], txn-recover: Recovering log 7 through 7\r\n",
      "2020-11-04T16:08:18.096+0000 I STORAGE  [initandlisten] WiredTiger message [1604506098:96715][1:0x7fbbb7cd1a40], txn-recover: Set global recovery timestamp: 0\r\n",
      "2020-11-04T16:08:18.118+0000 I RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)\r\n",
      "2020-11-04T16:08:18.153+0000 I CONTROL  [initandlisten] \r\n",
      "2020-11-04T16:08:18.153+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.\r\n",
      "2020-11-04T16:08:18.153+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.\r\n",
      "2020-11-04T16:08:18.153+0000 I CONTROL  [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.\r\n",
      "2020-11-04T16:08:18.153+0000 I CONTROL  [initandlisten] \r\n",
      "2020-11-04T16:08:18.179+0000 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/db/diagnostic.data'\r\n",
      "2020-11-04T16:08:18.181+0000 I REPL     [initandlisten] Did not find local voted for document at startup.\r\n",
      "2020-11-04T16:08:18.181+0000 I REPL     [initandlisten] Rollback ID is 1\r\n",
      "2020-11-04T16:08:18.181+0000 I REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset\r\n",
      "2020-11-04T16:08:18.182+0000 I NETWORK  [initandlisten] waiting for connections on port 27017\r\n",
      "2020-11-04T16:08:18.182+0000 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Replication has not yet been configured\r\n",
      "2020-11-04T16:08:18.182+0000 I CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: config.system.sessions does not exist\r\n",
      "2020-11-04T16:08:19.015+0000 I FTDC     [ftdc] Unclean full-time diagnostic data capture shutdown detected, found interim file, some metrics may have been lost. OK\r\n",
      "2020-11-04T16:13:18.182+0000 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Replication has not yet been configured\r\n",
      "2020-11-04T16:13:18.182+0000 I CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: config.system.sessions does not exist\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 30 mongo1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-04T16:08:18.245+0000 I REPL     [replexec-0] New replica set config in use: { _id: \"devrs\", version: 1, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: \"mongo2:27017\", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5fa2c6bb5354956582583364') } }\r\n",
      "2020-11-04T16:08:18.245+0000 I REPL     [replexec-0] This node is mongo2:27017 in the config\r\n",
      "2020-11-04T16:08:18.245+0000 I REPL     [replexec-0] transition to STARTUP2 from STARTUP\r\n",
      "2020-11-04T16:08:18.245+0000 I REPL     [replexec-0] Starting replication storage threads\r\n",
      "2020-11-04T16:08:18.247+0000 I REPL     [replexec-0] transition to RECOVERING from STARTUP2\r\n",
      "2020-11-04T16:08:18.247+0000 I REPL     [replexec-0] Starting replication fetcher thread\r\n",
      "2020-11-04T16:08:18.247+0000 I REPL     [replexec-0] Starting replication applier thread\r\n",
      "2020-11-04T16:08:18.247+0000 I REPL     [replexec-0] Starting replication reporter thread\r\n",
      "2020-11-04T16:08:18.248+0000 I REPL     [rsSync-0] Starting oplog application\r\n",
      "2020-11-04T16:08:18.249+0000 I REPL     [rsSync-0] transition to SECONDARY from RECOVERING\r\n",
      "2020-11-04T16:08:18.249+0000 I REPL     [rsSync-0] conducting a dry run election to see if we could be elected. current term: 6\r\n",
      "2020-11-04T16:08:18.249+0000 I REPL     [replexec-0] dry election run succeeded, running for election in term 7\r\n",
      "2020-11-04T16:08:18.251+0000 I REPL     [replexec-0] election succeeded, assuming primary role in term 7\r\n",
      "2020-11-04T16:08:18.252+0000 I REPL     [replexec-0] transition to PRIMARY from SECONDARY\r\n",
      "2020-11-04T16:08:18.252+0000 I REPL     [replexec-0] Resetting sync source to empty, which was :27017\r\n",
      "2020-11-04T16:08:18.252+0000 I REPL     [replexec-0] Entering primary catch-up mode.\r\n",
      "2020-11-04T16:08:18.252+0000 I REPL     [replexec-0] Exited primary catch-up mode.\r\n",
      "2020-11-04T16:08:18.252+0000 I REPL     [replexec-0] Stopping replication producer\r\n",
      "2020-11-04T16:08:20.252+0000 I REPL     [rsSync-0] transition to primary complete; database writes are now permitted\r\n",
      "2020-11-04T16:08:29.765+0000 I NETWORK  [listener] connection accepted from 172.19.0.1:54564 #1 (1 connection now open)\r\n",
      "2020-11-04T16:08:29.766+0000 I NETWORK  [conn1] received client metadata from 172.19.0.1:54564 conn1: { driver: { name: \"PyMongo\", version: \"3.11.0\" }, os: { type: \"Linux\", name: \"Linux\", architecture: \"x86_64\", version: \"5.4.39-linuxkit\" }, platform: \"CPython 3.8.5.final.0\" }\r\n",
      "2020-11-04T16:08:31.104+0000 I NETWORK  [listener] connection accepted from 172.19.0.1:54568 #2 (2 connections now open)\r\n",
      "2020-11-04T16:08:31.105+0000 I NETWORK  [conn2] received client metadata from 172.19.0.1:54568 conn2: { driver: { name: \"PyMongo\", version: \"3.11.0\" }, os: { type: \"Linux\", name: \"Linux\", architecture: \"x86_64\", version: \"5.4.39-linuxkit\" }, platform: \"CPython 3.8.5.final.0\" }\r\n",
      "2020-11-04T16:08:31.108+0000 I COMMAND  [conn2] initiate : no configuration specified. Using a default configuration for the set\r\n",
      "2020-11-04T16:08:31.108+0000 I COMMAND  [conn2] created this configuration for initiation : { _id: \"devrs\", version: 1, members: [ { _id: 0, host: \"mongo2:27017\" } ] }\r\n",
      "2020-11-04T16:08:31.108+0000 I REPL     [conn2] replSetInitiate admin command received from client\r\n",
      "2020-11-04T16:08:41.096+0000 I NETWORK  [listener] connection accepted from 172.19.0.1:54572 #3 (3 connections now open)\r\n",
      "2020-11-04T16:08:41.098+0000 I NETWORK  [conn3] received client metadata from 172.19.0.1:54572 conn3: { driver: { name: \"PyMongo\", version: \"3.11.0\" }, os: { type: \"Linux\", name: \"Linux\", architecture: \"x86_64\", version: \"5.4.39-linuxkit\" }, platform: \"CPython 3.8.5.final.0\" }\r\n",
      "2020-11-04T16:08:44.442+0000 I NETWORK  [listener] connection accepted from 172.19.0.1:54576 #4 (4 connections now open)\r\n",
      "2020-11-04T16:08:44.444+0000 I NETWORK  [conn4] received client metadata from 172.19.0.1:54576 conn4: { driver: { name: \"PyMongo\", version: \"3.11.0\" }, os: { type: \"Linux\", name: \"Linux\", architecture: \"x86_64\", version: \"5.4.39-linuxkit\" }, platform: \"CPython 3.8.5.final.0\" }\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 30 mongo2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-04T16:08:18.124+0000 I REPL     [replexec-0] New replica set config in use: { _id: \"devrs\", version: 1, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: \"mongo3:27017\", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5fa2cedecda5066af5fece76') } }\r\n",
      "2020-11-04T16:08:18.125+0000 I REPL     [replexec-0] This node is mongo3:27017 in the config\r\n",
      "2020-11-04T16:08:18.125+0000 I REPL     [replexec-0] transition to STARTUP2 from STARTUP\r\n",
      "2020-11-04T16:08:18.125+0000 I REPL     [replexec-0] Starting replication storage threads\r\n",
      "2020-11-04T16:08:18.126+0000 I NETWORK  [LogicalSessionCacheRefresh] Starting new replica set monitor for devrs/mongo3:27017\r\n",
      "2020-11-04T16:08:18.126+0000 I NETWORK  [listener] connection accepted from 172.19.0.2:47510 #2 (1 connection now open)\r\n",
      "2020-11-04T16:08:18.127+0000 I NETWORK  [conn2] received client metadata from 172.19.0.2:47510 conn2: { driver: { name: \"MongoDB Internal Client\", version: \"4.0.4\" }, os: { type: \"Linux\", name: \"Ubuntu\", architecture: \"x86_64\", version: \"16.04\" } }\r\n",
      "2020-11-04T16:08:18.127+0000 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Successfully connected to mongo3:27017 (1 connections now open to mongo3:27017 with a 5 second timeout)\r\n",
      "2020-11-04T16:08:18.127+0000 W NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set devrs\r\n",
      "2020-11-04T16:08:18.128+0000 I REPL     [replexec-0] transition to RECOVERING from STARTUP2\r\n",
      "2020-11-04T16:08:18.129+0000 I REPL     [replexec-0] Starting replication fetcher thread\r\n",
      "2020-11-04T16:08:18.129+0000 I REPL     [replexec-0] Starting replication applier thread\r\n",
      "2020-11-04T16:08:18.129+0000 I REPL     [rsSync-0] Starting oplog application\r\n",
      "2020-11-04T16:08:18.129+0000 I REPL     [rsSync-0] transition to SECONDARY from RECOVERING\r\n",
      "2020-11-04T16:08:18.130+0000 I REPL     [rsSync-0] conducting a dry run election to see if we could be elected. current term: 3\r\n",
      "2020-11-04T16:08:18.129+0000 I REPL     [replexec-0] Starting replication reporter thread\r\n",
      "2020-11-04T16:08:18.130+0000 I REPL     [replexec-1] dry election run succeeded, running for election in term 4\r\n",
      "2020-11-04T16:08:18.132+0000 I REPL     [replexec-0] election succeeded, assuming primary role in term 4\r\n",
      "2020-11-04T16:08:18.132+0000 I REPL     [replexec-0] transition to PRIMARY from SECONDARY\r\n",
      "2020-11-04T16:08:18.132+0000 I REPL     [replexec-0] Resetting sync source to empty, which was :27017\r\n",
      "2020-11-04T16:08:18.133+0000 I REPL     [replexec-0] Entering primary catch-up mode.\r\n",
      "2020-11-04T16:08:18.133+0000 I REPL     [replexec-0] Exited primary catch-up mode.\r\n",
      "2020-11-04T16:08:18.133+0000 I REPL     [replexec-0] Stopping replication producer\r\n",
      "2020-11-04T16:08:18.629+0000 W NETWORK  [LogicalSessionCacheRefresh] Unable to reach primary for set devrs\r\n",
      "2020-11-04T16:08:19.130+0000 W NETWORK  [LogicalSessionCacheRefresh] Unable to reach primary for set devrs\r\n",
      "2020-11-04T16:08:19.633+0000 W NETWORK  [LogicalSessionCacheRefresh] Unable to reach primary for set devrs\r\n",
      "2020-11-04T16:08:20.131+0000 I REPL     [rsSync-0] transition to primary complete; database writes are now permitted\r\n",
      "2020-11-04T16:08:20.135+0000 I NETWORK  [listener] connection accepted from 172.19.0.2:47512 #4 (2 connections now open)\r\n",
      "2020-11-04T16:08:20.135+0000 I NETWORK  [conn4] received client metadata from 172.19.0.2:47512 conn4: { driver: { name: \"MongoDB Internal Client\", version: \"4.0.4\" }, os: { type: \"Linux\", name: \"Ubuntu\", architecture: \"x86_64\", version: \"16.04\" } }\r\n",
      "2020-11-04T16:08:20.136+0000 I NETWORK  [LogicalSessionCacheRefresh] Successfully connected to mongo3:27017 (1 connections now open to mongo3:27017 with a 0 second timeout)\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 30 mongo3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}